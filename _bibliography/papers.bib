---
---

@string{CHI = {ACM Conference on Human Factors in Computing Systems}}
@string{CSCW = {Computer-Supported Cooperative Work}}
@string{NeurIPS = {Neural Information Processing Systems}}

@article{10.1145/3757521,
author = {Kaufman, Robert and Broukhim, Aaron and Haupt, Michael},
title = {WARNING This Contains Misinformation: The Effect of Cognitive Factors, Beliefs, and Personality on Misinformation Warning Tag Attitudes},
year = {2025},
issue_date = {November 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {9},
number = {7},
url = {https://doi.org/10.1145/3757521},
doi = {10.1145/3757521},
abstract = {Social media platforms enhance the propagation of online misinformation by providing large user bases with a quick means to share content. One way to disrupt the rapid dissemination of misinformation at scale is through warning tags, which label content as potentially false or misleading. However, past warning tag mitigation studies yield mixed results for diverse audiences. We hypothesize that personalizing warning tags to the individual characteristics of their diverse users may enhance mitigation effectiveness. To reach the goal of personalization, we need to understand how people differ and how those differences predict a person's attitudes and behaviors toward tags and tagged content. In this study, we leverage Amazon Mechanical Turk (n = 132) and undergraduate students (n = 112) to provide this foundational understanding. With all participants combined, we find attitudes towards warning tags and self-described behaviors are significantly influenced by factors such as Need for Cognitive Closure (NFCC), Political orientation, and Trust in Medical Scientists when controlled for covariates such as age and recruiting platform. Analyses of each sample further show that tag attitudes were influenced by Trust in Religious Leaders, and Big Five Inventory (BFI) traits for Openness and Conscientiousness. We synthesize these results into design insights and a future research agenda for more effective and personalized warning tags and misinformation mitigation strategies more generally.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = oct,
articleno = {CSCW340},
numpages = {32},
keywords = {bias, individual differences, misinformation, social media}
}

@inproceedings{10.1145/3706598.3713088,
author = {Kaufman, Robert A and Broukhim, Aaron and Kirsh, David and Weibel, Nadir},
title = {What Did My Car Say? Impact of Autonomous Vehicle Explanation Errors and Driving Context On Comfort, Reliance, Satisfaction, and Driving Confidence},
year = {2025},
isbn = {9798400713941},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3706598.3713088},
doi = {10.1145/3706598.3713088},
abstract = {Explanations for autonomous vehicle (AV) decisions may build trust, however, explanations can contain errors. In a simulated driving study (n = 232), we tested how AV explanation errors, driving context characteristics (perceived harm and driving difficulty), and personal traits (prior trust and expertise) affected a passenger’s comfort in relying on an AV, preference for control, confidence in the AV’s ability, and explanation satisfaction. Errors negatively affected all outcomes. Surprisingly, despite identical driving, explanation errors reduced ratings of the AV’s driving ability. Severity and potential harm amplified the negative impact of errors. Contextual harm and driving difficulty directly impacted outcome ratings and influenced the relationship between errors and outcomes. Prior trust and expertise were positively associated with outcome ratings. Results emphasize the need for accurate, contextually adaptive, and personalized AV explanations to foster trust, reliance, satisfaction, and confidence. We conclude with design, research, and deployment recommendations for trustworthy AV explanation systems.},
booktitle = {Proceedings of the 2025 CHI Conference on Human Factors in Computing Systems},
articleno = {89},
numpages = {17},
keywords = {Autonomous Vehicles, Explainable AI, AI Errors},
location = {
},
series = {CHI '25}
}

@article{haritaoglu2022using,
  title={Using deep learning with large aggregated datasets for COVID-19 classification from cough},
  author={Haritaoglu, Esin Darici and Rasmussen, Nicholas and Tan, Daniel CH and Xiao, Jaclyn and Chaudhari, Gunvant and Rajput, Akanksha and Govindan, Praveen and Canham, Christian and Chen, Wei and Yamaura, Minami and others},
  journal={arXiv preprint arXiv:2201.01669},
  year={2022}
}